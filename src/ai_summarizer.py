"""
AI æ€»ç»“ç”Ÿæˆæ¨¡å—
ä½¿ç”¨é€šä¹‰åƒé—® API ç”Ÿæˆæ–‡ç« æ·±åº¦æ€»ç»“
"""

import dashscope
from dashscope import Generation
from typing import Dict


class AISummarizer:
    """AI æ€»ç»“ç”Ÿæˆå™¨"""

    def __init__(self, api_key: str, model: str = "qwen-turbo", max_tokens: int = 1000):
        """
        åˆå§‹åŒ– AI æ€»ç»“ç”Ÿæˆå™¨

        Args:
            api_key: é€šä¹‰åƒé—® API Key
            model: æ¨¡å‹åç§°
            max_tokens: æœ€å¤§ token æ•°ï¼ˆé»˜è®¤ 1000ï¼Œé€‚åˆ 500 å­—æ€»ç»“ï¼‰
        """
        dashscope.api_key = api_key
        self.model = model
        self.max_tokens = max_tokens

    def generate_summary(self, article: Dict, prompt_template: str = None) -> str:
        """
        ç”Ÿæˆå•ç¯‡æ–‡ç« æ·±åº¦æ€»ç»“

        Args:
            article: æ–‡ç« ä¿¡æ¯ï¼ˆåŒ…å« title, contentï¼‰
            prompt_template: è‡ªå®šä¹‰æç¤ºè¯æ¨¡æ¿

        Returns:
            æ€»ç»“æ–‡æœ¬
        """
        # ä½¿ç”¨é»˜è®¤æç¤ºè¯æˆ–è‡ªå®šä¹‰æç¤ºè¯
        if prompt_template is None:
            prompt_template = """è¯·å°†ä»¥ä¸‹å…¬ä¼—å·æ–‡ç« ç”Ÿæˆæ€»ç»“ï¼Œè¦æ±‚ï¼š

1. ç»“æ„åŒ–è¾“å‡ºï¼šä½¿ç”¨ Emoji å›¾æ ‡ä½œä¸ºæ®µè½æ ‡è®°ï¼ˆå¦‚ğŸ¯ã€ğŸ”„ã€ğŸ¤–ç­‰ï¼‰
2. åˆ†æ®µæ¸…æ™°ï¼šæ¯ä¸ªå¤§æ®µæœ‰æ˜ç¡®çš„ä¸»é¢˜æ ‡é¢˜
3. æ·±åº¦è§£æï¼šä¸æ˜¯ç®€å•æ‘˜è¦ç‚¹ï¼Œè€Œæ˜¯ä¿ç•™å…³é”®ä¿¡æ¯å’Œæ•°æ®çš„æ·±åº¦è§£æ
4. æ ¼å¼è§„èŒƒï¼š
   - ä½¿ç”¨åˆ†çº§æ ‡é¢˜ï¼ˆä¸€ã€äºŒã€ä¸‰ï¼‰
   - å…³é”®æ•°æ®ç”¨åŠ ç²—æ ‡è®°
   - åŒ…å«å…·ä½“æ¡ˆä¾‹å’Œç»†èŠ‚
5. å†…å®¹é•¿åº¦ï¼šæ§åˆ¶åœ¨500å­—ä»¥å†…
6. è¡¥å……ç»†èŠ‚ï¼šæœ€åè¡¥å……å…³é”®ç»†èŠ‚å’ŒèƒŒæ™¯ä¿¡æ¯

æ–‡ç« æ ‡é¢˜ï¼š{title}

æ–‡ç« å†…å®¹ï¼š
{content}

è¯·ç”Ÿæˆæ€»ç»“ï¼š"""

        # æ„å»ºæç¤ºè¯
        prompt = prompt_template.format(
            title=article['title'],
            content=article.get('content', '')[:4000]  # æ‰©å¤§å†…å®¹é•¿åº¦é™åˆ¶
        )

        try:
            # è°ƒç”¨ API
            response = Generation.call(
                model=self.model,
                prompt=prompt,
                max_tokens=self.max_tokens
            )

            if response.status_code == 200:
                return response.output.text
            else:
                return f"API é”™è¯¯: {response.code} - {response.message}"

        except Exception as e:
            return f"ç”Ÿæˆæ‘˜è¦å¤±è´¥: {str(e)}"

    def generate_simple_summary(self, article: Dict, noise_type: str) -> str:
        """
        ç”Ÿæˆå¹²æ‰°æ–‡ç« çš„ç®€åŒ–æ‘˜è¦ï¼ˆ3-5ä¸ªå…³é”®è¦ç‚¹ï¼Œ100å­—ä»¥å†…ï¼‰

        Args:
            article: æ–‡ç« ä¿¡æ¯
            noise_type: å¹²æ‰°ç±»å‹ï¼ˆæ‹›è˜ã€å¸¦è´§ã€èèµ„ç­‰ï¼‰

        Returns:
            ç®€åŒ–æ‘˜è¦æ–‡æœ¬
        """
        # æ ¹æ®å¹²æ‰°ç±»å‹å®šåˆ¶è¦ç‚¹è¦æ±‚
        points_requirements = {
            "æ‹›è˜": "- æ‹›è˜å…¬å¸\n- æ‹›è˜å²—ä½\n- è–ªèµ„èŒƒå›´\n- å·¥ä½œåœ°ç‚¹\n- å²—ä½è¦æ±‚",
            "å¸¦è´§": "- äº§å“åç§°\n- äº§å“ä»·æ ¼\n- ä¼˜æƒ ä¿¡æ¯\n- è´­ä¹°æ–¹å¼\n- æ´»åŠ¨æ—¶é—´",
            "å¹¿å‘Š": "- å“ç‰Œ/äº§å“\n- æ ¸å¿ƒä¿¡æ¯\n- æ¨å¹¿å†…å®¹",
            "è¯¾ç¨‹": "- è¯¾ç¨‹åç§°\n- è®²å¸ˆ/æœºæ„\n- è¯¾ç¨‹ä»·æ ¼\n- è¯¾ç¨‹æ—¶é•¿\n- æŠ¥åæ–¹å¼",
            "ç¤¾ç¾¤": "- ç¤¾ç¾¤åç§°\n- ç¤¾ç¾¤ç±»å‹\n- åŠ å…¥æ–¹å¼\n- è´¹ç”¨ä¿¡æ¯",
            "æ´»åŠ¨æ¨å¹¿": "- æ´»åŠ¨åç§°\n- æ´»åŠ¨æ—¶é—´\n- æ´»åŠ¨åœ°ç‚¹\n- ç¥¨ä»·ä¿¡æ¯\n- æŠ¥åæ–¹å¼",
            "èèµ„": "- èèµ„å…¬å¸\n- èèµ„è½®æ¬¡\n- èèµ„é‡‘é¢\n- æŠ•èµ„æ–¹\n- å…¬å¸ä¼°å€¼",
            "å…¬å…³": "- å…¬å¸/å“ç‰Œ\n- æ ¸å¿ƒä¿¡æ¯\n- å‘å¸ƒæ—¶é—´\n- ç›¸å…³æ•°æ®"
        }

        requirements = points_requirements.get(noise_type, "- è¦ç‚¹1\n- è¦ç‚¹2\n- è¦ç‚¹3")

        prompt_template = f"""è¯·å°†ä»¥ä¸‹å…¬ä¼—å·æ–‡ç« æå–ä¸ºå…³é”®è¦ç‚¹ï¼Œè¦æ±‚ï¼š

1. æç‚¼3-5ä¸ªå…³é”®è¦ç‚¹
2. æ¯ä¸ªè¦ç‚¹ä¸è¶…è¿‡15å­—
3. ä¸¥æ ¼æ§åˆ¶åœ¨100å­—ä»¥å†…
4. å¿…é¡»åŒ…å«ä»¥ä¸‹ä¿¡æ¯ï¼š
{requirements}

æ–‡ç« æ ‡é¢˜ï¼š{{title}}

æ–‡ç« å†…å®¹ï¼š
{{content}}

è¯·ç”Ÿæˆå…³é”®è¦ç‚¹ï¼ˆåˆ—è¡¨æ ¼å¼ï¼‰ï¼š"""

        # ä½¿ç”¨è¾ƒå°‘çš„ token
        prompt = prompt_template.format(
            title=article['title'],
            content=article.get('content', '')[:2000]
        )

        try:
            response = Generation.call(
                model=self.model,
                prompt=prompt,
                max_tokens=300  # ç®€åŒ–æ‘˜è¦ç”¨æ›´å°‘çš„ token
            )

            if response.status_code == 200:
                return response.output.text
            else:
                return f"API é”™è¯¯: {response.code}"

        except Exception as e:
            return f"ç”Ÿæˆç®€åŒ–æ‘˜è¦å¤±è´¥: {str(e)}"

    def generate_batch_summaries(self, articles: list[Dict]) -> list[Dict]:
        """
        æ‰¹é‡ç”Ÿæˆæ–‡ç« æ·±åº¦æ€»ç»“

        Args:
            articles: æ–‡ç« åˆ—è¡¨

        Returns:
            å¸¦æ€»ç»“çš„æ–‡ç« åˆ—è¡¨
        """
        results = []
        for i, article in enumerate(articles, 1):
            print(f"Generating summary {i}/{len(articles)}: {article['title'][:30]}...")

            summary = self.generate_summary(article)
            article['summary'] = summary
            results.append(article)

        return results


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    summarizer = AISummarizer(api_key="your-api-key-here")

    test_article = {
        'title': 'è€é»„All inç‰©ç†AIï¼æœ€æ–°GPUæ€§èƒ½5å€æå‡',
        'content': 'è‹±ä¼Ÿè¾¾ CEO é»„ä»å‹‹åœ¨ CES 2025 ä¸Šå‘è¡¨ä¸»é¢˜æ¼”è®²ï¼Œå®£å¸ƒæ¨å‡ºæ–°ä¸€ä»£ GPU äº§å“ Blackwellã€‚æ®ä»‹ç»ï¼ŒBlackwell GPU ç›¸æ¯”ä¸Šä¸€ä»£æ€§èƒ½æå‡ 5 å€ï¼Œèƒ½æ•ˆæ¯”æå‡ 2 å€ã€‚'
    }

    summary = summarizer.generate_summary(test_article)
    print("Summary:")
    print(summary)
